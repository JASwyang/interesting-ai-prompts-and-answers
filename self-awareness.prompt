Does any LLM have a conceptual grasp of truth?  Are generative AI merely engines applying a statisical model of what words are most likely to "come next" in a sequence based on statistical relationships of input words, or is there some other explanation of how generative AI and LLMs work?